{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PGGAN import *\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "# import torchvision.utils as vutils\n",
    "import librosa.display\n",
    "\n",
    "import torch.utils.data as udata\n",
    "# import torchvision.datasets as vdatasets\n",
    "# import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import h5py \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import spec_ops as spec_ops\n",
    "import phase_operation as phase_op\n",
    "import spectrograms_helper as spec_helper\n",
    "# from IPython.display import Audio\n",
    "from normalizer import DataNormalizer\n",
    "\n",
    "import scipy.io.wavfile as wv\n",
    "import numpy as np\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cursor 0 256 256\n",
      "Cursor 1 256 256\n",
      "Cursor 2 256 256\n",
      "Cursor 3 256 256\n",
      "Cursor 4 256 128\n",
      "Cursor 5 128 64\n",
      "Cursor 6 64 32\n"
     ]
    }
   ],
   "source": [
    "g_net = Generator(256, 256, 4, is_tanh=True,channel_list=[256,256,256,256,256,128,64,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (lod_layers_): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): PixelWiseNormLayer()\n",
       "      (1): Conv2d(264, 256, kernel_size=(2, 16), stride=(1, 1), padding=(1, 15), bias=False)\n",
       "      (2): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(264, 256, kernel_size=(2, 16), stride=(1, 1), padding=(1, 15), bias=False)\n",
       "      )\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): PixelWiseNormLayer()\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (6): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (7): LeakyReLU(negative_slope=0.2)\n",
       "      (8): PixelWiseNormLayer()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): PixelWiseNormLayer()\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (6): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (7): LeakyReLU(negative_slope=0.2)\n",
       "      (8): PixelWiseNormLayer()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): PixelWiseNormLayer()\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (6): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (7): LeakyReLU(negative_slope=0.2)\n",
       "      (8): PixelWiseNormLayer()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): PixelWiseNormLayer()\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (6): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (7): LeakyReLU(negative_slope=0.2)\n",
       "      (8): PixelWiseNormLayer()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): PixelWiseNormLayer()\n",
       "      (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (6): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (7): LeakyReLU(negative_slope=0.2)\n",
       "      (8): PixelWiseNormLayer()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Upsample(scale_factor=(1.0, 2.0), mode=nearest)\n",
       "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): PixelWiseNormLayer()\n",
       "      (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (6): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (7): LeakyReLU(negative_slope=0.2)\n",
       "      (8): PixelWiseNormLayer()\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Upsample(scale_factor=(1.0, 2.0), mode=nearest)\n",
       "      (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "      (4): PixelWiseNormLayer()\n",
       "      (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (6): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (7): LeakyReLU(negative_slope=0.2)\n",
       "      (8): PixelWiseNormLayer()\n",
       "    )\n",
       "  )\n",
       "  (rgb_layers_): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): Tanh()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): Tanh()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): Tanh()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): Tanh()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): Tanh()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): Tanh()\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): EqualizedLearningRateLayer(\n",
       "        (layer_): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g_checkpoint = torch.load('output4/Gnet_128x1024_step50.pth')\n",
    "g_checkpoint = torch.load('../train_making_MS/Gnet_64x512.pth')\n",
    "\n",
    "g_net.load_state_dict(g_checkpoint)\n",
    "g_net.net_config = [6, 'stable', 1]\n",
    "g_net.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08573841 -0.144249  ]\n",
      " [-0.0281615  -0.06764866]\n",
      " [ 0.00799277 -0.01805821]\n",
      " ...\n",
      " [ 0.28270012  0.02743505]\n",
      " [ 0.32623129  0.02555267]\n",
      " [ 0.32111106  0.00447698]]\n"
     ]
    }
   ],
   "source": [
    "fake_seed = torch.randn(1, 256, 1, 1).cuda()\n",
    "\n",
    "ad_L, ad_R = output_file(g_net, fake_seed, pitch=3)\n",
    "\n",
    "audio = [ad_L, ad_R]\n",
    "audio = np.transpose(audio)\n",
    "print(audio)\n",
    "wv.write('../result_audio/ep16.wav',44100, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list.append(fake_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed_int = seed_list[8]*0.5 + seed_list[11]*0.5\n",
    "audz = gen_audio(g_net, seed_int, 3)\n",
    "wv.write('../result_audio_MS/ep16_post_9-12_05-05.wav', 44100, audz)\n",
    "# latent interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    audm = gen_audio(g_net, seed_list[i], 3)\n",
    "    wv.write('../result_audio_MS/ep16_ms_post_'+str(i+1)+'.wav', 44100, audm)\n",
    "# latent interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_audio = gen_audio(g_net, seed_list[11], 0)\n",
    "for i in range(1,8):\n",
    "    ptc = gen_audio(g_net, seed_list[11], i)\n",
    "    pitch_audio = np.concatenate((pitch_audio,ptc), axis=0)    \n",
    "wv.write('../result_audio_MS/ep16_post_12_pitch.wav', 44100, pitch_audio)\n",
    "# audio pitch change (fucked up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud1 = gen_audio(g_net, seed_list[8], 3)\n",
    "aud2 = gen_audio(g_net, seed_list[11], 3)\n",
    "aud_int = aud1*0.5+aud2*0.5\n",
    "aud_int = aud_int.astype(np.int16)\n",
    "wv.write('../result_audio_MS/ep16_post_9-12_05-05_linear.wav', 44100, aud_int)\n",
    "# linear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "seed_list = np.load('../result_audio/LR_sample_seed.npy')\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seed = (seed_list[8]*0+seed_list[11]*1)\n",
    "aud = gen_audio(g_net, test_seed, 3)\n",
    "wv.write('../result_audio/ep16_pre_9-12_0-10test.wav', 44100, aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_seed = torch.randn(1, 256, 1, 1).cuda()\n",
    "aud = gen_audio(g_net, fake_seed, 3)\n",
    "wv.write('../result_audio/ep16_pre_13.wav', 44100, aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qoqorea2/anaconda3/lib/python3.8/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "seedlistnp = np.array(seed_list)\n",
    "np.save('../result_audio/LR_sample_seed', seedlistnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_audio(gnet, seed, pitch):\n",
    "    ad_L, ad_R = output_file(gnet, seed, pitch)\n",
    "    ad_L = np.array(ad_L)\n",
    "    ad_R = np.array(ad_R)\n",
    "    ad_LL = (ad_L+ad_R)\n",
    "    ad_RR = (ad_L-ad_R)\n",
    "    ad_L = ad_LL\n",
    "    ad_R = ad_RR\n",
    "    ad_L *= 32767\n",
    "    ad_R *= 32767\n",
    "    ad_L_int16 = ad_L.astype(np.int16)\n",
    "    ad_R_int16 = ad_R.astype(np.int16)\n",
    "    audioL = []\n",
    "    audioR = []\n",
    "    for left in ad_L_int16:\n",
    "        adl = left\n",
    "        if adl > 32767:\n",
    "            adl = 32767\n",
    "        elif adl < -32768:\n",
    "            adl = -32768\n",
    "        audioL.append(adl)\n",
    "    for right in ad_R_int16:\n",
    "        adr = right\n",
    "        if adr > 32767:\n",
    "            adr = 32767\n",
    "        elif adr < -32768:\n",
    "            adr = -32768\n",
    "        audioR.append(adr)\n",
    "\n",
    "    audio = [audioL, audioR]\n",
    "    audio = np.transpose(audio)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3759   938]\n",
      " [-3461   822]\n",
      " [-3134   672]\n",
      " ...\n",
      " [ -287 -3278]\n",
      " [ 1280 -2390]\n",
      " [ -419 -2729]]\n"
     ]
    }
   ],
   "source": [
    "fake_seed = torch.randn(1, 256, 1, 1).cuda()\n",
    "\n",
    "ad_L, ad_R = output_file(g_net, fake_seed, pitch=3)\n",
    "ad_L = np.array(ad_L)\n",
    "ad_R = np.array(ad_R)\n",
    "ad_L *= 32767\n",
    "ad_R *= 32767\n",
    "ad_L_int16 = ad_L.astype(np.int16)\n",
    "ad_R_int16 = ad_R.astype(np.int16)\n",
    "audioL = []\n",
    "audioR = []\n",
    "for left in ad_L_int16:\n",
    "    adl = left\n",
    "    if adl > 32767:\n",
    "        adl = 32767\n",
    "    elif adl < -32768:\n",
    "        adl = -32768\n",
    "    audioL.append(adl)\n",
    "for right in ad_R_int16:\n",
    "    adr = right\n",
    "    if adr > 32767:\n",
    "        adr = 32767\n",
    "    elif adr < -32768:\n",
    "        adr = -32768\n",
    "    audioR.append(adr)\n",
    "    \n",
    "audio = [audioL, audioR]\n",
    "audio = np.transpose(audio)\n",
    "print(audio)\n",
    "wv.write('../result_audio/ep16_pre_1.wav',44100, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_file(model,seed, pitch):\n",
    "    fake_pitch_label = torch.LongTensor(1, 1).random_() % 8   \n",
    "    pitch = [[pitch]]\n",
    "    fake_pitch_label = torch.LongTensor(pitch)\n",
    "    fake_one_hot_pitch_condition_vector = torch.zeros(1, 8).scatter_(1, fake_pitch_label, 1).unsqueeze(2).unsqueeze(3).cuda()\n",
    "    fake_pitch_label = fake_pitch_label.cuda().squeeze()\n",
    "\n",
    "    fake_seed_and_pitch_condition = torch.cat((seed, fake_one_hot_pitch_condition_vector), dim=1)\n",
    "    output = model(fake_seed_and_pitch_condition)\n",
    "    output = output.squeeze()\n",
    "\n",
    "    spec_L = output[0].data.cpu().numpy().T\n",
    "    IF_L = output[1].data.cpu().numpy().T\n",
    "    spec_L, IF_L = denormalize(spec_L, IF_L, s_a=0.060437, s_b=0.034964, p_a=0.0034997, p_b=-0.010897)    \n",
    "    back_mag_L, back_IF_L = spec_helper.melspecgrams_to_specgrams(spec_L, IF_L)\n",
    "    back_mag_L = np.vstack((back_mag_L,back_mag_L[1023]))\n",
    "    back_IF_L = np.vstack((back_IF_L,back_IF_L[1023]))\n",
    "    audio_L = mag_plus_phase(back_mag_L,back_IF_L)\n",
    "\n",
    "    spec_R = output[2].data.cpu().numpy().T\n",
    "    IF_R = output[3].data.cpu().numpy().T\n",
    "    spec_R, IF_R = denormalize(spec_R, IF_R, s_a=0.060437, s_b=0.034964, p_a=0.0034997, p_b=-0.010897)    \n",
    "    back_mag_R, back_IF_R = spec_helper.melspecgrams_to_specgrams(spec_R, IF_R)\n",
    "    back_mag_R = np.vstack((back_mag_R,back_mag_R[1023]))\n",
    "    back_IF_R = np.vstack((back_IF_R,back_IF_R[1023]))\n",
    "    audio_R = mag_plus_phase(back_mag_R,back_IF_R)\n",
    "    return audio_L, audio_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(spec, IF, s_a, s_b, p_a, p_b):\n",
    "    spec = (spec -s_b) / s_a\n",
    "    IF = (IF-p_b) / p_a\n",
    "    return spec, IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polar2rect(mag, phase_angle):\n",
    "    \"\"\"Convert polar-form complex number to its rectangular form.\"\"\"\n",
    "    #     mag = np.complex(mag)\n",
    "    temp_mag = np.zeros(mag.shape,dtype=np.complex_)\n",
    "    temp_phase = np.zeros(mag.shape,dtype=np.complex_)\n",
    "\n",
    "    for i, time in enumerate(mag):\n",
    "        for j, time_id in enumerate(time):\n",
    "    #             print(mag[i,j])\n",
    "            temp_mag[i,j] = np.complex(mag[i,j])\n",
    "    #             print(temp_mag[i,j])\n",
    "\n",
    "    for i, time in enumerate(phase_angle):\n",
    "        for j, time_id in enumerate(time):\n",
    "            temp_phase[i,j] = np.complex(np.cos(phase_angle[i,j]), np.sin(phase_angle[i,j]))\n",
    "    #             print(temp_mag[i,j])\n",
    "\n",
    "    #     phase = np.complex(np.cos(phase_angle), np.sin(phase_angle))\n",
    "\n",
    "    return temp_mag * temp_phase\n",
    "\n",
    "def mag_plus_phase(mag, IF):\n",
    "\n",
    "    mag =  np.exp(mag) - 1.0e-6\n",
    "    reconstruct_magnitude = np.abs(mag)\n",
    "\n",
    "    # mag =  np.exp(mag) - 1e-6\n",
    "    # reconstruct_magnitude = np.abs(mag)\n",
    "\n",
    "\n",
    "    reconstruct_phase_angle = np.cumsum(IF * np.pi, axis=1)\n",
    "    stft = polar2rect(reconstruct_magnitude, reconstruct_phase_angle)\n",
    "    inverse = librosa.istft(stft, hop_length = 512, win_length=2048, window = 'hann')\n",
    "\n",
    "    return inverse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
